{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x182yUaaGOIx"
   },
   "source": [
    "### Download Flowers dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "USgEKN9GGf60"
   },
   "outputs": [],
   "source": [
    "#You can download the data manually as well instead of using 'wget'\n",
    "!wget http://download.tensorflow.org/example_images/flower_photos.tgz --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3cCPVwdxpDvR"
   },
   "outputs": [],
   "source": [
    "#Check if file is downloaded\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r9NeLYrOpIc0"
   },
   "outputs": [],
   "source": [
    "#Unzip the data\n",
    "!tar -xf flower_photos.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fd2Zz_mYrU7N"
   },
   "outputs": [],
   "source": [
    "#Check how data is organized\n",
    "!ls -l flower_photos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lz0v83zDhs2y"
   },
   "source": [
    "### Build batch generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-da8Sz_BpnpI"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQQ7Oksaq7tI"
   },
   "outputs": [],
   "source": [
    "#Define some parameters\n",
    "img_size = 60\n",
    "img_depth = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBkyCTo1qWMy"
   },
   "source": [
    "Create an ImageDataGenerator object, it can also split data between train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bkUsCc6zp7Kp"
   },
   "outputs": [],
   "source": [
    "#ImageDataGenerator declaration with 20% data as test (80% for training)\n",
    "img_generator= tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3BVmtXdrHyh"
   },
   "source": [
    "ImageDataGenerator can read images directory and also resize them if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IkCVDrPOqDjE"
   },
   "outputs": [],
   "source": [
    "#Build training generator. \n",
    "train_generator = img_generator.flow_from_directory('flower_photos',\n",
    "                                                    target_size=(img_size, img_size),\n",
    "                                                    subset='training',\n",
    "                                                    batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Z7_0KoJGRDM"
   },
   "outputs": [],
   "source": [
    "#Build test generator\n",
    "test_generator = img_generator.flow_from_directory('flower_photos',\n",
    "                                                   target_size=(img_size, img_size),                                                   \n",
    "                                                   subset='validation',\n",
    "                                                   batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZnOY195Pt7mn"
   },
   "outputs": [],
   "source": [
    "type(train_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCpXm9s4rjM1"
   },
   "source": [
    "ImageDataGenerator returns 64 images and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUhNi9Krrpq7"
   },
   "outputs": [],
   "source": [
    "#Lets check the features (images) and Labels (flower class) returned by ImageDataGenerator\n",
    "X, y = next(train_generator)\n",
    "\n",
    "print('Input features shape', X.shape)\n",
    "print('Actual labels shape', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1NUb1CcQx_Zo"
   },
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_iJgvxvh32gt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.unique(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "es0UPokXxIKM"
   },
   "outputs": [],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xDV8kVGpOi_w"
   },
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1DOwu8Bhs29"
   },
   "source": [
    "### Build CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tWQJ4SzZhs2-"
   },
   "outputs": [],
   "source": [
    "#Clear any previous model from memory\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#Initialize model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#normalize data\n",
    "model.add(tf.keras.layers.BatchNormalization(input_shape=(img_size,img_size,3,)))\n",
    "\n",
    "#Add Conv Layer\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "#normalize data\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add Conv Layer\n",
    "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "#normalize data\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add Max Pool layer\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "#Add Dense Layers after flattening the data\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "\n",
    "#Add Dropout\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "#Add Output Layer\n",
    "model.add(tf.keras.layers.Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GsuEXbofhs3D"
   },
   "outputs": [],
   "source": [
    "#Specify Loass and Optimizer\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0V1E9Ua1tUPP"
   },
   "outputs": [],
   "source": [
    "#Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0v7UlgC5hs3g"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cklB73X8yCvt"
   },
   "outputs": [],
   "source": [
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('flowers.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ldJt7GHB5dtQ"
   },
   "outputs": [],
   "source": [
    "2939//64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7YGqTxKQhs3l"
   },
   "outputs": [],
   "source": [
    "model.fit(train_generator,\n",
    "          epochs=200,\n",
    "          steps_per_epoch= 2939//64,  #Number of batches per epoch\n",
    "          validation_data=test_generator,\n",
    "          validation_steps = 731//64, \n",
    "          callbacks=[model_checkpoint]) #Number of test images//batch_size"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2b. Image Classification - Flowers.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
